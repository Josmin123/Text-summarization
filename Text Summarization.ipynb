{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c9ccc06",
   "metadata": {},
   "source": [
    "# What is text summarization?\n",
    "### Text summarization is hte process of distilling the most important information form a source of text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723e9611",
   "metadata": {},
   "source": [
    "## why automatic text summarization?\n",
    "- summaries reduce reading time\n",
    "- when researching documents,summaries make hte selection process easier\n",
    "- Automatic summarization improves effectiveness of indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e054ca1c",
   "metadata": {},
   "source": [
    "## Steps\n",
    "- Text cleaning\n",
    "- sentence tokenization\n",
    "- word summarization\n",
    "- word-frequency table \n",
    "- summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0b67914",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spacy in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (3.6.1)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (0.10.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (1.23.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (8.1.11)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (22.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (2.0.9)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (65.6.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (2.4.7)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (2.1.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.7.1)\n",
      "Requirement already satisfied: pydantic-core==2.4.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.4.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.5.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.1)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5431f79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-sm==3.6.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 12.8/12.8 MB 1.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.7.0,>=3.6.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from en-core-web-sm==3.6.0) (3.6.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (22.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.11)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.7)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.64.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.8)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (5.2.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.23.5)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (65.6.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.1)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.9)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.4.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.7.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.1)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.6.0\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64ec9702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d62d4c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"In school, most of us had to understand and convert long text articles into their succinct summaries, the technique we used then was to grasp the underlying idea of the text and reproduce the summary that would cover all the important points. This is similar to the idea of abstractive text summarization, wherein the machine learning model would output the main idea of the input text using similar words but not exact sentences from the input.The second type of summarization is extractive summarization in which the model output can be considered a subset of the input text which conveys the main idea of the input article, making it an important application of text summarization in NLP. A personal analogy that I would like to share is, you can consider extractive summarization as highlighting important points of a reference paper that you are trying to understand. Extractive summarization is a commonly used approach in text summarization NLP techniques, which aims to extract and present the most relevant information from the original text while preserving its meaning.As you may have guessed extractive summarization is simpler to model than abstractive summarization, this is because in abstractive summarization the model is expected to understand language and its nuances to make any meaning out of it and produce a valid summary. Whereas in extractive summarization using some form of scoring (which we would discuss in detail later in this article), the model has to threshold and output the most important sentences of the input itself.Naturally, there is more research available for extractive summarization than abstractive summarization. In this article, we would look into extractive summarization in further detail.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ea511de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stopwords=list(STOP_WORDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "73cb4808",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f9017ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "97460a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In', 'school', ',', 'most', 'of', 'us', 'had', 'to', 'understand', 'and', 'convert', 'long', 'text', 'articles', 'into', 'their', 'succinct', 'summaries', ',', 'the', 'technique', 'we', 'used', 'then', 'was', 'to', 'grasp', 'the', 'underlying', 'idea', 'of', 'the', 'text', 'and', 'reproduce', 'the', 'summary', 'that', 'would', 'cover', 'all', 'the', 'important', 'points', '.', 'This', 'is', 'similar', 'to', 'the', 'idea', 'of', 'abstractive', 'text', 'summarization', ',', 'wherein', 'the', 'machine', 'learning', 'model', 'would', 'output', 'the', 'main', 'idea', 'of', 'the', 'input', 'text', 'using', 'similar', 'words', 'but', 'not', 'exact', 'sentences', 'from', 'the', 'input', '.', 'The', 'second', 'type', 'of', 'summarization', 'is', 'extractive', 'summarization', 'in', 'which', 'the', 'model', 'output', 'can', 'be', 'considered', 'a', 'subset', 'of', 'the', 'input', 'text', 'which', 'conveys', 'the', 'main', 'idea', 'of', 'the', 'input', 'article', ',', 'making', 'it', 'an', 'important', 'application', 'of', 'text', 'summarization', 'in', 'NLP', '.', 'A', 'personal', 'analogy', 'that', 'I', 'would', 'like', 'to', 'share', 'is', ',', 'you', 'can', 'consider', 'extractive', 'summarization', 'as', 'highlighting', 'important', 'points', 'of', 'a', 'reference', 'paper', 'that', 'you', 'are', 'trying', 'to', 'understand', '.', 'Extractive', 'summarization', 'is', 'a', 'commonly', 'used', 'approach', 'in', 'text', 'summarization', 'NLP', 'techniques', ',', 'which', 'aims', 'to', 'extract', 'and', 'present', 'the', 'most', 'relevant', 'information', 'from', 'the', 'original', 'text', 'while', 'preserving', 'its', 'meaning', '.', 'As', 'you', 'may', 'have', 'guessed', 'extractive', 'summarization', 'is', 'simpler', 'to', 'model', 'than', 'abstractive', 'summarization', ',', 'this', 'is', 'because', 'in', 'abstractive', 'summarization', 'the', 'model', 'is', 'expected', 'to', 'understand', 'language', 'and', 'its', 'nuances', 'to', 'make', 'any', 'meaning', 'out', 'of', 'it', 'and', 'produce', 'a', 'valid', 'summary', '.', 'Whereas', 'in', 'extractive', 'summarization', 'using', 'some', 'form', 'of', 'scoring', '(', 'which', 'we', 'would', 'discuss', 'in', 'detail', 'later', 'in', 'this', 'article', ')', ',', 'the', 'model', 'has', 'to', 'threshold', 'and', 'output', 'the', 'most', 'important', 'sentences', 'of', 'the', 'input', 'itself', '.', 'Naturally', ',', 'there', 'is', 'more', 'research', 'available', 'for', 'extractive', 'summarization', 'than', 'abstractive', 'summarization', '.', 'In', 'this', 'article', ',', 'we', 'would', 'look', 'into', 'extractive', 'summarization', 'in', 'further', 'detail', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens=[token.text for token in doc]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "804c0fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\\n \\n \\n '"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation= punctuation+'\\n'+' '\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8430da77",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequencies={}\n",
    "for word in doc:\n",
    "    if word.text.lower() not in stopwords:\n",
    "        if word.text.lower() not in punctuation:\n",
    "            if word.text not in word_frequencies.keys():\n",
    "                word_frequencies[word.text]=1\n",
    "            else:\n",
    "                word_frequencies[word.text]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0edfc00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'school': 1, 'understand': 3, 'convert': 1, 'long': 1, 'text': 8, 'articles': 1, 'succinct': 1, 'summaries': 1, 'technique': 1, 'grasp': 1, 'underlying': 1, 'idea': 4, 'reproduce': 1, 'summary': 2, 'cover': 1, 'important': 4, 'points': 2, 'similar': 2, 'abstractive': 4, 'summarization': 14, 'machine': 1, 'learning': 1, 'model': 5, 'output': 3, 'main': 2, 'input': 5, 'words': 1, 'exact': 1, 'sentences': 2, 'second': 1, 'type': 1, 'extractive': 6, 'considered': 1, 'subset': 1, 'conveys': 1, 'article': 3, 'making': 1, 'application': 1, 'NLP': 2, 'personal': 1, 'analogy': 1, 'like': 1, 'share': 1, 'consider': 1, 'highlighting': 1, 'reference': 1, 'paper': 1, 'trying': 1, 'Extractive': 1, 'commonly': 1, 'approach': 1, 'techniques': 1, 'aims': 1, 'extract': 1, 'present': 1, 'relevant': 1, 'information': 1, 'original': 1, 'preserving': 1, 'meaning': 2, 'guessed': 1, 'simpler': 1, 'expected': 1, 'language': 1, 'nuances': 1, 'produce': 1, 'valid': 1, 'form': 1, 'scoring': 1, 'discuss': 1, 'detail': 2, 'later': 1, 'threshold': 1, 'Naturally': 1, 'research': 1, 'available': 1, 'look': 1}\n"
     ]
    }
   ],
   "source": [
    "print(word_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a5c58a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_frequency=max(word_frequencies.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "211281b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "600c98de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in word_frequencies.keys():\n",
    "    word_frequencies[word]=word_frequencies[word]/max_frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "64e208c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'school': 0.07142857142857142, 'understand': 0.21428571428571427, 'convert': 0.07142857142857142, 'long': 0.07142857142857142, 'text': 0.5714285714285714, 'articles': 0.07142857142857142, 'succinct': 0.07142857142857142, 'summaries': 0.07142857142857142, 'technique': 0.07142857142857142, 'grasp': 0.07142857142857142, 'underlying': 0.07142857142857142, 'idea': 0.2857142857142857, 'reproduce': 0.07142857142857142, 'summary': 0.14285714285714285, 'cover': 0.07142857142857142, 'important': 0.2857142857142857, 'points': 0.14285714285714285, 'similar': 0.14285714285714285, 'abstractive': 0.2857142857142857, 'summarization': 1.0, 'machine': 0.07142857142857142, 'learning': 0.07142857142857142, 'model': 0.35714285714285715, 'output': 0.21428571428571427, 'main': 0.14285714285714285, 'input': 0.35714285714285715, 'words': 0.07142857142857142, 'exact': 0.07142857142857142, 'sentences': 0.14285714285714285, 'second': 0.07142857142857142, 'type': 0.07142857142857142, 'extractive': 0.42857142857142855, 'considered': 0.07142857142857142, 'subset': 0.07142857142857142, 'conveys': 0.07142857142857142, 'article': 0.21428571428571427, 'making': 0.07142857142857142, 'application': 0.07142857142857142, 'NLP': 0.14285714285714285, 'personal': 0.07142857142857142, 'analogy': 0.07142857142857142, 'like': 0.07142857142857142, 'share': 0.07142857142857142, 'consider': 0.07142857142857142, 'highlighting': 0.07142857142857142, 'reference': 0.07142857142857142, 'paper': 0.07142857142857142, 'trying': 0.07142857142857142, 'Extractive': 0.07142857142857142, 'commonly': 0.07142857142857142, 'approach': 0.07142857142857142, 'techniques': 0.07142857142857142, 'aims': 0.07142857142857142, 'extract': 0.07142857142857142, 'present': 0.07142857142857142, 'relevant': 0.07142857142857142, 'information': 0.07142857142857142, 'original': 0.07142857142857142, 'preserving': 0.07142857142857142, 'meaning': 0.14285714285714285, 'guessed': 0.07142857142857142, 'simpler': 0.07142857142857142, 'expected': 0.07142857142857142, 'language': 0.07142857142857142, 'nuances': 0.07142857142857142, 'produce': 0.07142857142857142, 'valid': 0.07142857142857142, 'form': 0.07142857142857142, 'scoring': 0.07142857142857142, 'discuss': 0.07142857142857142, 'detail': 0.14285714285714285, 'later': 0.07142857142857142, 'threshold': 0.07142857142857142, 'Naturally': 0.07142857142857142, 'research': 0.07142857142857142, 'available': 0.07142857142857142, 'look': 0.07142857142857142}\n"
     ]
    }
   ],
   "source": [
    "print(word_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "15d0dddb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In school, most of us had to understand and convert long text articles into their succinct summaries, the technique we used then was to grasp the underlying idea of the text and reproduce the summary that would cover all the important points., This is similar to the idea of abstractive text summarization, wherein the machine learning model would output the main idea of the input text using similar words but not exact sentences from the input., The second type of summarization is extractive summarization in which the model output can be considered a subset of the input text which conveys the main idea of the input article, making it an important application of text summarization in NLP., A personal analogy that I would like to share is, you can consider extractive summarization as highlighting important points of a reference paper that you are trying to understand., Extractive summarization is a commonly used approach in text summarization NLP techniques, which aims to extract and present the most relevant information from the original text while preserving its meaning., As you may have guessed extractive summarization is simpler to model than abstractive summarization, this is because in abstractive summarization the model is expected to understand language and its nuances to make any meaning out of it and produce a valid summary., Whereas in extractive summarization using some form of scoring (which we would discuss in detail later in this article), the model has to threshold and output the most important sentences of the input itself., Naturally, there is more research available for extractive summarization than abstractive summarization., In this article, we would look into extractive summarization in further detail.]\n"
     ]
    }
   ],
   "source": [
    "sentence_tokens=[sent for sent in doc.sents]\n",
    "print(sentence_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e87ffbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_score={}\n",
    "for sent in sentence_tokens:\n",
    "    for word in sent:\n",
    "        if word.text.lower() in word_frequencies.keys():\n",
    "            if sent not in sentence_score.keys():\n",
    "                sentence_score[sent]=word_frequencies[word.text.lower()]\n",
    "            else:\n",
    "                sentence_score[sent]+=word_frequencies[word.text.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b1500d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{In school, most of us had to understand and convert long text articles into their succinct summaries, the technique we used then was to grasp the underlying idea of the text and reproduce the summary that would cover all the important points.: 3.0,\n",
       " This is similar to the idea of abstractive text summarization, wherein the machine learning model would output the main idea of the input text using similar words but not exact sentences from the input.: 5.142857142857143,\n",
       " The second type of summarization is extractive summarization in which the model output can be considered a subset of the input text which conveys the main idea of the input article, making it an important application of text summarization in NLP.: 7.285714285714285,\n",
       " A personal analogy that I would like to share is, you can consider extractive summarization as highlighting important points of a reference paper that you are trying to understand.: 2.714285714285715,\n",
       " Extractive summarization is a commonly used approach in text summarization NLP techniques, which aims to extract and present the most relevant information from the original text while preserving its meaning.: 4.42857142857143,\n",
       " As you may have guessed extractive summarization is simpler to model than abstractive summarization, this is because in abstractive summarization the model is expected to understand language and its nuances to make any meaning out of it and produce a valid summary.: 5.7142857142857135,\n",
       " Whereas in extractive summarization using some form of scoring (which we would discuss in detail later in this article), the model has to threshold and output the most important sentences of the input itself.: 3.5,\n",
       " Naturally, there is more research available for extractive summarization than abstractive summarization.: 2.857142857142857,\n",
       " In this article, we would look into extractive summarization in further detail.: 1.857142857142857}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "041d2852",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "981a0786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_lenght = int(len(sentence_tokens)*0.3)\n",
    "select_lenght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "18bdd817",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary=nlargest(select_lenght,sentence_score,key=sentence_score.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b158872f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[The second type of summarization is extractive summarization in which the model output can be considered a subset of the input text which conveys the main idea of the input article, making it an important application of text summarization in NLP.,\n",
       " As you may have guessed extractive summarization is simpler to model than abstractive summarization, this is because in abstractive summarization the model is expected to understand language and its nuances to make any meaning out of it and produce a valid summary.]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ba9c2d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summary=[word.text for word in summary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7fa26d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary=' '.join(final_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a8caa24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The second type of summarization is extractive summarization in which the model output can be considered a subset of the input text which conveys the main idea of the input article, making it an important application of text summarization in NLP. As you may have guessed extractive summarization is simpler to model than abstractive summarization, this is because in abstractive summarization the model is expected to understand language and its nuances to make any meaning out of it and produce a valid summary.\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9023823e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1738"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bdd86c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1841"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb4bf81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
